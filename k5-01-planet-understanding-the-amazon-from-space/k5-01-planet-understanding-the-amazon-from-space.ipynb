{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planet: Understanding the Amazon from Space\n",
    "\n",
    "https://www.kaggle.com/c/planet-understanding-the-amazon-from-space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem/data description\n",
    "\n",
    "Every minute, the world loses an area of forest the size of 48 football fields. And deforestation in the Amazon Basin accounts for the largest share, contributing to reduced biodiversity, habitat loss, climate change, and other devastating effects. But better data about the location of deforestation and human encroachment on forests can help governments and local stakeholders respond more quickly and effectively\n",
    "\n",
    "Planet, designer and builder of the world’s largest constellation of Earth-imaging satellites, will soon be collecting daily imagery of the entire land surface of the earth at 3-5 meter resolution. While considerable research has been devoted to tracking changes in forests, it typically depends on coarse-resolution imagery from Landsat (30 meter pixels) or MODIS (250 meter pixels). This limits its effectiveness in areas where small-scale deforestation or forest degradation dominate.\n",
    "\n",
    "In this competition, Planet and its Brazilian partner SCCON are challenging Kagglers to label satellite image chips with atmospheric conditions and various classes of land cover/land use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "\n",
    "df_train = pd.read_csv('input/train_v2.csv')\n",
    "\n",
    "label_map = {'agriculture': 14,\n",
    " 'artisinal_mine': 5,\n",
    " 'bare_ground': 1,\n",
    " 'blooming': 3,\n",
    " 'blow_down': 0,\n",
    " 'clear': 10,\n",
    " 'cloudy': 16,\n",
    " 'conventional_mine': 2,\n",
    " 'cultivation': 4,\n",
    " 'habitation': 9,\n",
    " 'haze': 6,\n",
    " 'partly_cloudy': 13,\n",
    " 'primary': 7,\n",
    " 'road': 11,\n",
    " 'selective_logging': 12,\n",
    " 'slash_burn': 8,\n",
    " 'water': 15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cache_data(data, path):\n",
    "    if os.path.isdir(os.path.dirname(path)):\n",
    "        file = open(path, 'wb')\n",
    "        pickle.dump(data, file, protocol=4)\n",
    "        file.close()\n",
    "    else:\n",
    "        print('Directory doesnt exists')\n",
    "\n",
    "def restore_data(path):\n",
    "    data = dict()\n",
    "    if os.path.isfile(path):\n",
    "        file = open(path, 'rb')\n",
    "        data = pickle.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [00:42<00:00, 962.48it/s] \n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('input/train-jpg/{}.jpg'.format(f))\n",
    "    img = cv2.resize(img, dsize=(64, 64))\n",
    "    x_train.append(img)\n",
    "\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    y_train.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(x_train, np.float32) / 255.\n",
    "y_train = np.array(y_train, np.uint8)\n",
    "\n",
    "cache_data(x_train, './x_train.dump')\n",
    "cache_data(y_train, './y_train.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = restore_data('./x_train.dump')\n",
    "y_train = restore_data('./y_train.dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, sess, lr=0.001):\n",
    "        self.sess = sess\n",
    "        self.lr = lr\n",
    "        self.build_model()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "    def build_model(self):\n",
    "        self.X = tf.placeholder(shape=[None, 64, 64, 3], dtype=tf.float32)\n",
    "        self.Y = tf.placeholder(shape=[None, 17], dtype=tf.float32)\n",
    "        self.dropout = tf.placeholder(dtype=tf.float32)\n",
    "      \n",
    "        filt1_1 = tf.Variable(tf.random_normal([3, 3, 3, 32], stddev=0.01))\n",
    "        filt1_2 = tf.Variable(tf.random_normal([3, 3, 32, 32], stddev=0.01))\n",
    "        \n",
    "        filt2_1 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "        filt2_2 = tf.Variable(tf.random_normal([3, 3, 64, 64], stddev=0.01))\n",
    "        \n",
    "        filt3_1 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "        filt3_2 = tf.Variable(tf.random_normal([3, 3, 128, 128], stddev=0.01))\n",
    "        \n",
    "        filt4_1 = tf.Variable(tf.random_normal([3, 3, 128, 256], stddev=0.01))\n",
    "        filt4_2 = tf.Variable(tf.random_normal([3, 3, 256, 256], stddev=0.01))\n",
    "        \n",
    "        fc_W1 = tf.Variable(tf.random_normal([4*4*256, 512], stddev=0.01))\n",
    "        fc_W2 = tf.Variable(tf.random_normal([512, 17], stddev=0.01))\n",
    "        \n",
    "        scale = tf.Variable(tf.ones([3]))\n",
    "        beta = tf.Variable(tf.zeros([3]))\n",
    "        batch_mean, batch_var = tf.nn.moments(self.X, [0])\n",
    "        self.X_bn = tf.nn.batch_normalization(self.X, batch_mean, batch_var, beta, scale, 1e-3)\n",
    "\n",
    "        self.conv1_1 = tf.nn.relu(tf.nn.conv2d(self.X_bn, filt1_1, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.conv1_2 = tf.nn.relu(tf.nn.conv2d(self.conv1_1, filt1_2, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.pool1 = tf.nn.max_pool(self.conv1_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        self.conv2_1 = tf.nn.relu(tf.nn.conv2d(self.pool1, filt2_1, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.conv2_2 = tf.nn.relu(tf.nn.conv2d(self.conv2_1, filt2_2, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.pool2 = tf.nn.max_pool(self.conv2_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        self.conv3_1 = tf.nn.relu(tf.nn.conv2d(self.pool2, filt3_1, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.conv3_2 = tf.nn.relu(tf.nn.conv2d(self.conv3_1, filt3_2, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        self.conv3_1 = tf.nn.relu(tf.nn.conv2d(self.pool2, filt3_1, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.conv3_2 = tf.nn.relu(tf.nn.conv2d(self.conv3_1, filt3_2, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.pool3 = tf.nn.max_pool(self.conv3_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    " \n",
    "        self.conv4_1 = tf.nn.relu(tf.nn.conv2d(self.pool3, filt4_1, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.conv4_2 = tf.nn.relu(tf.nn.conv2d(self.conv4_1, filt4_2, strides=[1, 1, 1, 1], padding='SAME'))\n",
    "        self.pool4 = tf.nn.max_pool(self.conv4_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        self.fc1 = tf.reshape(self.pool4, [-1, fc_W1.get_shape().as_list()[0]])       \n",
    "        self.fc1 = tf.nn.relu(tf.matmul(self.fc1, fc_W1))\n",
    "        self.fc1 = tf.nn.dropout(self.fc1, self.dropout)\n",
    "        \n",
    "        scale1 = tf.Variable(tf.ones([512]))\n",
    "        beta1 = tf.Variable(tf.zeros([512]))\n",
    "        batch_mean1, batch_var1 = tf.nn.moments(self.fc1, [0])\n",
    "        self.fc1_bn = tf.nn.batch_normalization(self.fc1, batch_mean1, batch_var1, beta1, scale1, 1e-3)\n",
    "        \n",
    "        self.fc2 = tf.matmul(self.fc1_bn, fc_W2)\n",
    "        self.pred = tf.nn.sigmoid(self.fc2)\n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=self.fc2, labels=self.Y), axis=1))\n",
    "        self.train = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.cost)\n",
    "    \n",
    "    def fit(self, X, Y, epochs=10, batch_size=128, dropout=0.5):\n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0 \n",
    "            \n",
    "            for step in range(0, len(X), batch_size):\n",
    "                batch_mask = np.random.choice(len(X), batch_size) # For dataset shuffle\n",
    "\n",
    "                feed_dict = {self.X: X[batch_mask], \n",
    "                             self.Y: Y[batch_mask], self.dropout: dropout}\n",
    "\n",
    "                _, c = self.sess.run([self.train, self.cost], feed_dict=feed_dict)\n",
    "                avg_cost += c\n",
    "            \n",
    "            avg_cost = avg_cost / (len(X) / batch_size)    \n",
    "            print(\"epoch: {} cost: {:.5f}\".format(epoch, avg_cost))\n",
    "        print(\"Optimization Finished!\")\n",
    "        \n",
    "    def pred_data(self, X, batch_size=256):\n",
    "        preds = []\n",
    "        for step in tqdm(range(0, len(X), batch_size)):\n",
    "            feed_dict = {self.X: X[step:step+batch_size], \n",
    "                         self.dropout: 1}\n",
    "\n",
    "            pred_batch = self.sess.run(self.pred, feed_dict=feed_dict)\n",
    "            \n",
    "            for pred in pred_batch:\n",
    "                preds.append(pred)\n",
    "        \n",
    "        return preds\n",
    "        \n",
    "    def save_model(self, path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.sess, path)\n",
    "        \n",
    "    def restore_model(self, path):\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            print ('load learning')\n",
    "            saver.restore(self.sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 cost: 0.27877\n",
      "epoch: 1 cost: 0.25972\n",
      "epoch: 2 cost: 0.26545\n",
      "epoch: 3 cost: 0.25072\n",
      "epoch: 4 cost: 0.25836\n",
      "epoch: 5 cost: 0.26969\n",
      "epoch: 6 cost: 0.24484\n",
      "epoch: 7 cost: 0.25185\n",
      "epoch: 8 cost: 0.22585\n",
      "epoch: 9 cost: 0.24122\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=512, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_model('./model/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.restore_model('./model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [01:00<00:00, 1017.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for f, tags in tqdm(df_test.values, miniters=1000):\n",
    "    img = cv2.imread('input/test-jpg/{}.jpg'.format(f))\n",
    "    img = cv2.resize(img, dsize=(64, 64))\n",
    "    x_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = np.array(x_test, np.float32) / 255.\n",
    "cache_data(x_test, './x_test.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = restore_data('./x_test.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:26<00:00,  9.10it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = np.array(model.pred_data(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = ['blow_down',\n",
    " 'bare_ground',\n",
    " 'conventional_mine',\n",
    " 'blooming',\n",
    " 'cultivation',\n",
    " 'artisinal_mine',\n",
    " 'haze',\n",
    " 'primary',\n",
    " 'slash_burn',\n",
    " 'habitation',\n",
    " 'clear',\n",
    " 'road',\n",
    " 'selective_logging',\n",
    " 'partly_cloudy',\n",
    " 'agriculture',\n",
    " 'water',\n",
    " 'cloudy']\n",
    "\n",
    "pred = pd.DataFrame(pred, columns = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61191/61191 [02:10<00:00, 467.69it/s]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "thres = [0.07, 0.17, 0.2, 0.04, 0.23, 0.33, 0.24, 0.22, 0.1, 0.19, 0.23, 0.24, 0.12, 0.14, 0.25, 0.26, 0.16]\n",
    "for i in tqdm(range(pred.shape[0]), miniters=1000):\n",
    "    a = pred.ix[[i]]\n",
    "    a = a.apply(lambda x: x > thres, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    result.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_5</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_6</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_8</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_9</td>\n",
       "      <td>primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_10</td>\n",
       "      <td>primary partly_cloudy agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_12</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_13</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_14</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "      <td>primary clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_17</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_18</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_19</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_20</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_21</td>\n",
       "      <td>primary clear water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_22</td>\n",
       "      <td>primary partly_cloudy agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_23</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_24</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_25</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_26</td>\n",
       "      <td>primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_27</td>\n",
       "      <td>primary clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_28</td>\n",
       "      <td>primary clear agriculture water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_29</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61161</th>\n",
       "      <td>file_9972</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61162</th>\n",
       "      <td>file_9973</td>\n",
       "      <td>primary clear agriculture water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61163</th>\n",
       "      <td>file_9974</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61164</th>\n",
       "      <td>file_9975</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61165</th>\n",
       "      <td>file_9976</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61166</th>\n",
       "      <td>file_9977</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61167</th>\n",
       "      <td>file_9978</td>\n",
       "      <td>primary partly_cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61168</th>\n",
       "      <td>file_9979</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61169</th>\n",
       "      <td>file_998</td>\n",
       "      <td>primary clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61170</th>\n",
       "      <td>file_9980</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61171</th>\n",
       "      <td>file_9981</td>\n",
       "      <td>primary clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61172</th>\n",
       "      <td>file_9982</td>\n",
       "      <td>primary habitation clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61173</th>\n",
       "      <td>file_9983</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61174</th>\n",
       "      <td>file_9984</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61175</th>\n",
       "      <td>file_9985</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>file_9986</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61177</th>\n",
       "      <td>file_9987</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61178</th>\n",
       "      <td>file_9988</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61179</th>\n",
       "      <td>file_9989</td>\n",
       "      <td>primary clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61180</th>\n",
       "      <td>file_999</td>\n",
       "      <td>primary clear road agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61181</th>\n",
       "      <td>file_9990</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61182</th>\n",
       "      <td>file_9991</td>\n",
       "      <td>primary clear agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61183</th>\n",
       "      <td>file_9992</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61184</th>\n",
       "      <td>file_9993</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>file_9994</td>\n",
       "      <td>primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61186</th>\n",
       "      <td>file_9995</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61187</th>\n",
       "      <td>file_9996</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61188</th>\n",
       "      <td>file_9997</td>\n",
       "      <td>primary clear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61189</th>\n",
       "      <td>file_9998</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61190</th>\n",
       "      <td>file_9999</td>\n",
       "      <td>primary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_name                                       tags\n",
       "0         test_0                  primary clear agriculture\n",
       "1         test_1                              primary clear\n",
       "2         test_2                      primary partly_cloudy\n",
       "3         test_3                  primary clear agriculture\n",
       "4         test_4                      primary partly_cloudy\n",
       "5         test_5                              primary clear\n",
       "6         test_6                      primary partly_cloudy\n",
       "7         test_7                              primary clear\n",
       "8         test_8                  primary clear agriculture\n",
       "9         test_9                                    primary\n",
       "10       test_10          primary partly_cloudy agriculture\n",
       "11       test_11                  primary clear agriculture\n",
       "12       test_12                                     cloudy\n",
       "13       test_13                  primary clear agriculture\n",
       "14       test_14                  primary clear agriculture\n",
       "15       test_15                              primary clear\n",
       "16       test_16             primary clear road agriculture\n",
       "17       test_17                      primary partly_cloudy\n",
       "18       test_18                  primary clear agriculture\n",
       "19       test_19                              primary clear\n",
       "20       test_20                  primary clear agriculture\n",
       "21       test_21                        primary clear water\n",
       "22       test_22          primary partly_cloudy agriculture\n",
       "23       test_23                                     cloudy\n",
       "24       test_24                      primary partly_cloudy\n",
       "25       test_25                              primary clear\n",
       "26       test_26                              primary water\n",
       "27       test_27             primary clear road agriculture\n",
       "28       test_28            primary clear agriculture water\n",
       "29       test_29                  primary clear agriculture\n",
       "...          ...                                        ...\n",
       "61161  file_9972                              primary clear\n",
       "61162  file_9973            primary clear agriculture water\n",
       "61163  file_9974                  primary clear agriculture\n",
       "61164  file_9975                              primary clear\n",
       "61165  file_9976                  primary clear agriculture\n",
       "61166  file_9977                              primary clear\n",
       "61167  file_9978                      primary partly_cloudy\n",
       "61168  file_9979                              primary clear\n",
       "61169   file_998             primary clear road agriculture\n",
       "61170  file_9980                              primary clear\n",
       "61171  file_9981             primary clear road agriculture\n",
       "61172  file_9982  primary habitation clear road agriculture\n",
       "61173  file_9983                              primary clear\n",
       "61174  file_9984                              primary clear\n",
       "61175  file_9985                              primary clear\n",
       "61176  file_9986                              primary clear\n",
       "61177  file_9987                  primary clear agriculture\n",
       "61178  file_9988                              primary clear\n",
       "61179  file_9989             primary clear road agriculture\n",
       "61180   file_999             primary clear road agriculture\n",
       "61181  file_9990                              primary clear\n",
       "61182  file_9991                  primary clear agriculture\n",
       "61183  file_9992                              primary clear\n",
       "61184  file_9993                              primary clear\n",
       "61185  file_9994                              primary water\n",
       "61186  file_9995                                     cloudy\n",
       "61187  file_9996                              primary clear\n",
       "61188  file_9997                              primary clear\n",
       "61189  file_9998                                     cloudy\n",
       "61190  file_9999                                    primary\n",
       "\n",
       "[61191 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('input/sample_submission_v2.csv')\n",
    "df_test['tags'] = result\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future work/exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is nothing as good as a discussion item to get an insight into this.   \n",
    "https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/35902  \n",
    "https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/discussion/35797  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}